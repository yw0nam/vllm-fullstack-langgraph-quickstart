"""
Chat interface module
ë©”ì¸ ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ì™€ ë©”ì‹œì§€ ì²˜ë¦¬ë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.
"""

import os
import streamlit as st
import traceback
from langchain_core.messages import HumanMessage
from .session_state import reset_research_progress
from .event_processor import EventStreamProcessor
from .response_processor import ResponseProcessor


def validate_configuration():
    """í˜„ì¬ ëª¨ë¸ ë° ê²€ìƒ‰ ì„¤ì •ì´ ìœ íš¨í•œì§€ í™•ì¸í•©ë‹ˆë‹¤."""
    errors = []

    # Model validation
    model_type = st.session_state.model_type
    if model_type == "vllm":
        if not os.getenv("MODEL_API_KEY") or not os.getenv("MODEL_API_URL"):
            errors.append(
                "vllmì„ ì‚¬ìš©í•˜ë ¤ë©´ .env íŒŒì¼ì— MODEL_API_KEYì™€ MODEL_API_URLì´ ì„¤ì •ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."
            )
    elif model_type == "gemini":
        google_key = (
            os.getenv("GOOGLE_API_KEY") or st.session_state.user_google_api_key.strip()
        )
        if not google_key:
            errors.append("geminië¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Google API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # Search validation
    search_type = st.session_state.search_type
    if search_type == "tavily":
        tavily_key = (
            os.getenv("TAVILY_API_KEY") or st.session_state.user_tavily_api_key.strip()
        )
        if not tavily_key:
            errors.append("tavily ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ë ¤ë©´ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    elif search_type == "google":
        google_key = (
            os.getenv("GOOGLE_API_KEY") or st.session_state.user_google_api_key.strip()
        )
        if not google_key:
            errors.append("google ê²€ìƒ‰ì„ ì‚¬ìš©í•˜ë ¤ë©´ Google API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    return errors


class ChatInterface:
    """ì±„íŒ… ì¸í„°í˜ì´ìŠ¤ í´ë˜ìŠ¤"""

    def __init__(self, graph, sidebar_manager):
        self.graph = graph
        self.sidebar_manager = sidebar_manager
        self.event_processor = EventStreamProcessor(graph, sidebar_manager)
        self.response_processor = ResponseProcessor(graph, sidebar_manager)

    def render_chat_history(self):
        """ì´ì „ ëŒ€í™” ê¸°ë¡ì„ í™”ë©´ì— í‘œì‹œí•©ë‹ˆë‹¤."""
        for message in st.session_state.messages:
            with st.chat_message(message["role"]):
                st.markdown(message["content"])

    def handle_user_input(self):
        """ì‚¬ìš©ì ì…ë ¥ì„ ì²˜ë¦¬í•˜ê³  AI ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        if prompt := st.chat_input("ì–´ë–¤ ì£¼ì œì— ëŒ€í•´ ë¦¬ì„œì¹˜í•´ ë“œë¦´ê¹Œìš”?"):
            # ì„¤ì • ìœ íš¨ì„± ê²€ì‚¬
            config_errors = validate_configuration()
            if config_errors:
                st.error("ì„¤ì • ì˜¤ë¥˜ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤:")
                for error in config_errors:
                    st.error(f"â€¢ {error}")
                st.info("ì‚¬ì´ë“œë°”ì—ì„œ ì„¤ì •ì„ í™•ì¸í•˜ê³  í•„ìš”í•œ API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
                return

            # ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ê¸°ë¡í•˜ê³  í™”ë©´ì— í‘œì‹œ
            st.session_state.messages.append({"role": "user", "content": prompt})
            with st.chat_message("user"):
                st.markdown(prompt)

            # ì§„í–‰ ìƒí™© ì´ˆê¸°í™”
            reset_research_progress()

            # ì‚¬ì´ë“œë°” ì´ˆê¸° ìƒíƒœ ì—…ë°ì´íŠ¸
            self.sidebar_manager.initialize_sidebar_state()

            # ì–´ì‹œìŠ¤í„´íŠ¸ì˜ ë‹µë³€ì´ í‘œì‹œë  ì˜ì—­
            with st.chat_message("assistant"):
                self._process_ai_response(prompt)

    def _process_ai_response(self, prompt):
        """AI ì‘ë‹µì„ ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        # í™˜ê²½ë³€ìˆ˜ì™€ ì„¸ì…˜ ìƒíƒœì—ì„œ API í‚¤ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤
        google_api_key = (
            os.getenv("GOOGLE_API_KEY") or st.session_state.user_google_api_key.strip()
        )
        tavily_api_key = (
            os.getenv("TAVILY_API_KEY") or st.session_state.user_tavily_api_key.strip()
        )

        config = {
            "configurable": {
                "thread_id": st.session_state.thread_id,
                "search_type": st.session_state.search_type,
                "model_type": st.session_state.model_type,
                "google_api_key": google_api_key,
                "tavily_api_key": tavily_api_key,
            }
        }
        final_answer = ""

        try:
            # ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬
            collected_data, stream_error = self.event_processor.process_stream(
                prompt, config
            )

            if stream_error:
                raise stream_error

            # ìŠ¤íŠ¸ë¦¼ ì™„ë£Œ í›„ ìµœì¢… ì²˜ë¦¬
            self.sidebar_manager.update_status("ğŸ”„ í›„ì²˜ë¦¬ ì¤‘", "ê²°ê³¼ ì •ë¦¬ ì¤‘...")

            final_answer = collected_data.get("final_answer", "")

            # ìµœì¢… ë‹µë³€ì´ ì—¬ì „íˆ ì—†ìœ¼ë©´ ì¼ë°˜ invoke ì‹œë„
            if not final_answer:
                final_answer = self.response_processor.fallback_invoke(prompt, config)

            # <think> íƒœê·¸ ë¶„ë¦¬ ë° ê²°ê³¼ ë Œë”ë§
            if final_answer:
                main_answer, reasoning_text = (
                    self.response_processor.separate_thinking_and_answer(final_answer)
                )

                # ìµœì¢… ìƒíƒœ ì—…ë°ì´íŠ¸
                self.sidebar_manager.update_status("âœ… ì™„ë£Œ", "ë¦¬ì„œì¹˜ ì™„ë£Œ!")

                # ê²°ê³¼ ë Œë”ë§
                self.response_processor.render_final_result(
                    main_answer, reasoning_text, collected_data
                )
            else:
                st.markdown("### ğŸ“‹ ìµœì¢… ë¦¬ì„œì¹˜ ê²°ê³¼")
                st.markdown("ë¦¬ì„œì¹˜ë¥¼ ì™„ë£Œí–ˆì§€ë§Œ ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        except Exception as e:
            final_answer = self._handle_error_recovery(e, prompt, config)

        # ìµœì¢… ë‹µë³€ì„ ì„¸ì…˜ ê¸°ë¡ì— ì €ì¥
        if final_answer:
            clean_answer = self.response_processor.clean_answer_for_session(
                final_answer
            )
            st.session_state.messages.append(
                {"role": "assistant", "content": clean_answer}
            )

    def _handle_error_recovery(self, error, prompt, config):
        """ì—ëŸ¬ ë°œìƒ ì‹œ ë³µêµ¬ë¥¼ ì‹œë„í•©ë‹ˆë‹¤."""
        self.sidebar_manager.update_status("âŒ ì˜¤ë¥˜ ë°œìƒ", f"ì—ëŸ¬: {str(error)}")
        st.error(f"âŒ ì¹˜ëª…ì  ì—ëŸ¬ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(error)}")
        st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

        # ì—ëŸ¬ ë°œìƒ ì‹œ ì¼ë°˜ ëª¨ë“œë¡œ ì‹œë„
        try:
            self.sidebar_manager.update_status(
                "ğŸ”„ ë³µêµ¬ ì‹œë„", "ì¼ë°˜ ëª¨ë“œë¡œ ì¬ì‹œë„ ì¤‘..."
            )

            result = self.graph.invoke(
                {"messages": [HumanMessage(content=prompt)]}, config
            )

            final_answer = ""
            if "messages" in result and result["messages"]:
                for msg in reversed(result["messages"]):
                    if (
                        hasattr(msg, "content")
                        and msg.content
                        and msg.content != prompt
                    ):
                        final_answer = msg.content
                        break

            # reasoning ë¶„ë¦¬
            main_answer, reasoning_text = (
                self.response_processor.separate_thinking_and_answer(final_answer)
            )

            self.sidebar_manager.update_status(
                "âœ… ì™„ë£Œ (ì¼ë°˜ ëª¨ë“œ)", "ì¼ë°˜ ëª¨ë“œë¡œ ì™„ë£Œ"
            )

            # ìµœì¢… ë‹µë³€ ë¨¼ì €
            st.markdown("### ğŸ“‹ ìµœì¢… ë¦¬ì„œì¹˜ ê²°ê³¼")
            st.markdown(main_answer or "ë‹µë³€ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

            # Reasoning ë‚˜ì¤‘ì— (ì°¸ì¡° ë¬¸ì„œ ì „ì—)
            if reasoning_text:
                st.markdown("---")
                st.markdown("### ğŸ§  AIì˜ ì‚¬ê³  ê³¼ì •")
                with st.expander("ğŸ’­ Reasoning ê³¼ì • ë³´ê¸°", expanded=False):
                    st.markdown(reasoning_text)

            return final_answer

        except Exception as e2:
            self.sidebar_manager.update_status(
                "âŒ ì‹¬ê°í•œ ì˜¤ë¥˜", f"ë³µêµ¬ ë¶ˆê°€ëŠ¥í•œ ì—ëŸ¬: {str(e2)}"
            )
            st.error(f"âŒ ì¼ë°˜ ëª¨ë“œì—ì„œë„ ì—ëŸ¬ ë°œìƒ: {str(e2)}")
            st.error(f"ìƒì„¸ ì˜¤ë¥˜: {traceback.format_exc()}")

            final_answer = "ì£„ì†¡í•©ë‹ˆë‹¤. ìš”ì²­ì„ ì²˜ë¦¬í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            st.markdown("### ğŸ“‹ ìµœì¢… ë¦¬ì„œì¹˜ ê²°ê³¼")
            st.markdown(final_answer)

            return final_answer
